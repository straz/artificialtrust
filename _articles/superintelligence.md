---
layout: article
title: Don&rsquo;t let superintelligence distract you
released: true
status: ready
created_date: 2022-09-03
defs: [delicious, reach]
---
{% include figure.html filename="spray.jpg" imgclass="col-md-2" %}

### The sex appeal of superintelligence

The idea that AIs can become superintelligent[^1] and kill us all is
gaining momentum among AI pundits. It's shiny, it's appealing, it's
super fun to write about, and so much more fun to watch in movies.

Superintelligence is sexy because itâ€™s the romantic fantasy enemy you
wish you had.

AI poses a number of threats (and opportunities, to be sure) varying
in urgency and potency. On that scale, I'm pretty convinced
superintelligence is a red herring.

### More like hidden mold

I tend to agree with machine learning pioneer Andrew Ng who said
"I donâ€™t work on preventing AI from turning evil for the same reason
that I donâ€™t work on the problem of overpopulation on the planet
Mars."[^2]

It's just not the most pressing problem we face. AI causes real
problems for real people today, and not because of superintelligence.
These problems are darker, more urgent, more relevant, and demand more
attention.

These problems are like having a house with hidden mold. [Cleaning
it up]({{ '../definitions/delicious' | relative-url }}) is not sexy at
all. It would make a terrible plot for an action movie. Given the
choice, I totally understand why pundits and the journalists who
follow them play up the superintelligence tale.

Ignoring mold can eventually make a house unlivable. Ignoring the
actual AI threats we live with today would be more dangerous to
humanity than evil killer robots.

### The evolution of the threat board

Automobiles have posed benefits and threats to our civilization, but
the nature of how we perceive those threats has evolved over time.

For nearly a century after the invention of the automobile, people saw
its dominant threat play out mostly in terms of highway safety. We
sought security through legal battles and engineering breakthroughs
around crumple zones, traffic signals, seat belts, antilock brakes,
and exploding gas tanks.

In the latter half of the century, automobiles gradually turned our
attention to threats to our oil supply, mostly in the middle east. We
sought security through complex geopolitics and sometimes wars to
protect our dependence on petroleum.

Finally, after so much effort on the first two threats, we are only
recently coming to terms with climate change. The climate narrative is
a latecomer to the threat board. It has been largely ignored for a
century.


### Artificially trustworthy

Cancerous stupidity is the mundane but very real enemy we face today.

It is not that AIs are too smart for us, it's that they are profoundly
stupid. They create the illusion of trustworthiness, when they are
anything but.  As Douglas Hofstadter said, they are "not just clueless
but cluelessly clueless."[^3] They have no idea, he says, that they
have no idea.

AIs are terribly brittle and error-prone under certain conditions.
The nature of their failures are corrosive to our society, because
they corrupt the information we rely on to make good decisions.  AIs
behave poorly when

 * they amplify and perpetuate harmful bias
 * they create torrents of information pollution, contaminating our world with strong false signals at scale
 * they are defenseless against attack by adversaries, and are easily manipulated
 * the problems they tackle are shifted from what they were trained for, and they don't realize it
 * they incur extreme environmental and financial costs[^4]
 * they are given [long reach]({{ '../definitions/reach' | relative-url }}) 
 problems, for which training is not possible
 * they are put in positions of authority without critical accountability or meaningful checks and balances.
 * their opacity becomes reason for us to follow them blindly and without recourse


Not only are they limited, but we are setting ourselves up to put our
full trust in them without protecting ourselves adequately for when
they inevitably fail us.

### So what

AI threats are not an external enemy to fear and defend against, but
insider threats woven into the fabric of our civilization and already
growing among us. The safeguards we seek should not be a Maginot line
against a fantasy invader. We need to take stock of the corruption we
see today, understand the forces that govern its growth, and make
informed countermeasures.

[^1]: 
    Bostrom, N. (2014).
	[*Superintelligence: Paths, Dangers, 
	Strategies.*](https://www.amazon.com/gp/product/0198739834)
	Oxford University Press.

[^2]:
    [*What's Next in Deep Learning*](https://youtu.be/jZTxDeoaJvA?t=3762).
	Quotation starts at 1h:02m of 2h:06m.
	<!-- video title: GPU Technology Conference 2015 day 3: What's Next in Deep Learning -->

[^3]:
    Hofstadter, D. (June 9, 2022). [*Artificial neural networks today are not 
	conscious.*](https://www.economist.com/by-invitation/2022/06/09/artificial-neural-networks-today-are-not-conscious-according-to-douglas-hofstadter)
    The Economist.

[^4]:
    Bender et al. (2021). *On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? ðŸ¦œ*. 
	[https://doi.org/10.1145/3442188.3445922](https://doi.org/10.1145/3442188.3445922)


<style>
#fnref\:5, .reversefootnote { display: none}
#fn\:5::marker {  color: transparent !important;}
</style>

[^5]

[^5]: *image credit:* [Crystal de PassillÃ©-Chabot](https://unsplash.com/es/@cchabot?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)
