---
layout: article
title: Fatal Darwinism
released: true
defs: [semantic]
arts: [cyber, kryptonite]
---

Neural nets work on a fairly straightforward principal of Darwinism.
They are trained by rewarding correct responses, and punishing
incorrect ones.

Darwinism relies on two conditions: (1) the decision-maker faces the
fatal effects of poor decisions, and (2) the individual's suffering is
inconsequential as long as the species is sustained. This is all fine
and good to create life on Earth as we know it. It is not fine and
good when we deploy AIs in situations that have high-stakes impact on
people's lives, because neither of these conditions are true.

In nature, errors in a neural net are tolerated as long as they don't
happen too frequently.  For organisms, each individual is its own neural net, 
perhaps one of billions of copies of a species.

If one of them makes a fatal mistake, while it's certainly bad news
for that individual, the species it belongs to is typically not
threatened. In fact, if the environment is fairly stable and the
errors don't happen too frequently, the species will likely benefit
from the selective pressure, which in turn improves that neural net,
slowly, over time.

When we deploy artificial neural nets, they too will inevitably make
errors.  If the stakes are low, the systems we build are not
threatened by the occasional error. And neither are we, the humans who
interact with such systems.  For example, if an AI decides to show a
pet food commercial to someone who doesn't own any pets, that's really
not a big deal.

The stakes are high when decisions are made that affect healthcare,
justice, and money, or in other words, life, liberty, and the pursuit
of happiness.

A single mistake here causes no harm to the AI, which has no stake
in the outcome. But it is absolutely devastating to the human whose
life it affects. 







